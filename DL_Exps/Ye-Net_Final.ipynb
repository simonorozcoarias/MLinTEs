{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ye-Net_Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTACIÓN DE LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc, ndimage, signal\n",
    "import numpy\n",
    "import numpy as np\n",
    "import random\n",
    "import ntpath\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from keras import optimizers \n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras.layers import Lambda, Layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, UpSampling2D\n",
    "from keras.layers.core import Reshape\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from time import time\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D,AveragePooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam,Adagrad,Nadam,Adamax,Adam,Adadelta,RMSprop\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras import optimizers \n",
    "from keras import regularizers\n",
    "from keras.layers import Lambda, Layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, UpSampling2D\n",
    "from keras.initializers import Constant, RandomNormal, glorot_normal\n",
    "from keras.layers.core import Reshape\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import *\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import glob\n",
    "from scipy import misc, ndimage, signal\n",
    "import numpy\n",
    "import random\n",
    "import ntpath\n",
    "import skimage\n",
    "from skimage.util.shape import view_as_blocks, view_as_windows\n",
    "import tensorflow as tf\n",
    "from tensorflow import clip_by_value\n",
    "import matplotlib as mpl\n",
    "from keras import optimizers \n",
    "from keras import regularizers\n",
    "from keras.layers.core import Reshape\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "from tensorflow import clip_by_value\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "from tensorflow.keras import layers, regularizers, initializers, activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRABAJO SOBRE LA CPU DADO QUE LA GPU ESTÉ OCUPADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USANDO LA CPU\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LECTURA DE LAS IMÁGENES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura forma 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ésta es la forma estandar que hemos venido usando para leer las imágenes y agruparlas en bloques para que sean usadas en la red, divididas tanto en entrenamiento como en validación y test. Y las etiquetas generadas [0 1] [1 0] para ser usadas con una función de activación sotwmax con una salida de dos clases o neuronas. \n",
    "\n",
    "Aquí train2 significa que los 4000 pares cover-stego se le aumentó con las 10000 de la base de datos BOWS2, en éste caso la base de datos se ha venido trabajando con el algoritmo esteganográfico S-UNIWARD con una carga de o.4bpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        #I=np.float32(I)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "#S-UNIWARD 0.4bpp\n",
    "\n",
    "#Train Images\n",
    "Xc = load_images('/media/ia/Datos1/DocReinel/DATABASES/BRASbase/train2/cover/*.pgm')\n",
    "Xs = load_images('/media/ia/Datos1/DocReinel/DATABASES/BRASbase/train2/stego/*.pgm')\n",
    "#Validation Images\n",
    "Yc = load_images('/media/ia/Datos1/DocReinel/DATABASES/BRASbase/valid/cover/*.pgm')\n",
    "Ys = load_images('/media/ia/Datos1/DocReinel/DATABASES/BRASbase/valid/stego/*.pgm')\n",
    "#Test Images\n",
    "Zc = load_images('/media/ia/Datos1/DocReinel/DATABASES/BRASbase/test/cover/*.pgm')\n",
    "Zs = load_images('/media/ia/Datos1/DocReinel/DATABASES/BRASbase/test/stego/*.pgm')\n",
    "\n",
    "X = (numpy.vstack((Xc, Xs)))\n",
    "Y = (numpy.vstack((Yc, Ys)))\n",
    "Z = (numpy.vstack((Zc, Zs)))\n",
    "\n",
    "Xt = (numpy.hstack(([0]*len(Xc), [1]*len(Xs))))\n",
    "Yt = (numpy.hstack(([0]*len(Yc), [1]*len(Ys))))\n",
    "Zt = (numpy.hstack(([0]*len(Zc), [1]*len(Zs))))\n",
    "\n",
    "Xt = np_utils.to_categorical(Xt, 2)\n",
    "Yt = np_utils.to_categorical(Yt, 2)\n",
    "Zt = np_utils.to_categorical(Zt, 2)\n",
    "\n",
    "idx=np.arange(len(X))\n",
    "random.shuffle(idx)\n",
    "\n",
    "X=X[idx]\n",
    "Xt=Xt[idx]\n",
    "\n",
    "X=np.rollaxis(X,1,4)  #channel axis shifted to last axis\n",
    "print (X.shape)\n",
    "Y=np.rollaxis(Y,1,4)  #channel axis shifted to last axis\n",
    "print (Y.shape)\n",
    "Z=np.rollaxis(Z,1,4)  #channel axis shifted to last axis\n",
    "print (Z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura forma 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el objetivo de que la lectura sea muchísimo más rápida se ha guardado la base de datos en archivos .npy como se podrá ver en la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No compilar\n",
    "#Guardamos los datos para luego leerlos muchisimo más rápido\n",
    "PATH = \"/media/ia/Datos1/DocReinel/DATABASES/BRASbase/S-Uniward0_4bpp_14000train_1000valid_5000test_pair_cs/\"\n",
    "\n",
    "#Train\n",
    "np.save(PATH+'X.npy', X)\n",
    "np.save(PATH+'Xt.npy', Xt)\n",
    "#Valid\n",
    "np.save(PATH+'Y.npy', Y)\n",
    "np.save(PATH+'Yt.npy', Yt)\n",
    "#Test\n",
    "np.save(PATH+'Z.npy', Z)\n",
    "np.save(PATH+'Zt.npy', Zt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego sólo hay que cargar los archivos .npy los cuales lo hacen extremadamente rápido comparado con la forma de lectura 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ruta de las imágenes\n",
    "PATH = \"/media/ia/Datos1/DocReinel/DATABASES/BRASbase/S-Uniward0_4bpp_14000train_1000valid_5000test_pair_cs/\"\n",
    "\n",
    "#Train\n",
    "X = np.load(PATH+'X.npy')\n",
    "Xt= np.load(PATH+'Xt.npy')\n",
    "#Valid\n",
    "Y = np.load(PATH+'Y.npy')\n",
    "Yt= np.load(PATH+'Yt.npy')\n",
    "#Test\n",
    "Z = np.load(PATH+'Z.npy')\n",
    "Zt= np.load(PATH+'Zt.npy')\n",
    "\n",
    "#Tamaños de los datos y de las etiquetas\n",
    "print (X.shape)\n",
    "print (Xt.shape)\n",
    "print (Y.shape)\n",
    "print (Yt.shape)\n",
    "print (Z.shape)\n",
    "print (Zt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LECTURA Y/O CARGA DE LOS 30 FILTROS SRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################SRM FILTER\n",
    "srm_weights = np.load('SRM_Kernels.npy')\n",
    "biasSRM=numpy.ones(30)\n",
    "print (srm_weights.shape)\n",
    "##################################################TLU ACTIVATION FUNCTION\n",
    "T3 = 3;\n",
    "def TLU3(x):\n",
    "    tlu3 = K.tanh(x)*T3\n",
    "    return tlu3\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# CREACIÓN DE LA FUNCIÓN TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Entradas\n",
    "\n",
    "Modelo diseñado.\n",
    "\n",
    "El valor del batch_size.\n",
    "\n",
    "La cantidad de épocas.\n",
    "\n",
    "El nombre del modelo.\n",
    "\n",
    "@Salidas\n",
    "\n",
    "Entrenar el modelo con los parametros ingresados.\n",
    "\n",
    "Guardar los modelos por épocas.\n",
    "\n",
    "Al final evaluar el modelo con la última época entrenada sobre los datos de prueba o Test.\n",
    "\n",
    "Guardar gráficos de las precisiones obtenidas en entrenamiento y validación, así como de la perdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, batch_size, epochs, model_name=\"\"):\n",
    "    log_dir=\"logs/\"+model_name+\"_\"+\"{}\".format(time())\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir)\n",
    "    filepath = log_dir+\"/saved-model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', save_best_only=False, mode='max')\n",
    "    model.reset_states()\n",
    "\n",
    "    history=model.fit(X, Xt, epochs=epochs, \n",
    "                      callbacks=[tensorboard,checkpoint], \n",
    "                      batch_size=batch_size,validation_data=(Y, Yt),verbose=1)\n",
    "    \n",
    "    metrics = model.evaluate(Z, Zt, verbose=0)\n",
    "    \n",
    "    #Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "    plt.grid()\n",
    "    plt.savefig('./Accuracy_YeNet.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    #Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "    plt.grid()\n",
    "    plt.savefig('./Loss_YeNet.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    return {k:v for k,v in zip (model.metrics_names, metrics)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREACIÓN DEL MODELO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO FINAL, MEJORES RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model_A(num_classes, img_size=256, compile=True):\n",
    "    tf.keras.backend.clear_session()\n",
    "    print (\"using\",num_classes,\"classes\")\n",
    "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
    "    \n",
    "    #Layer 1\n",
    "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=TLU3, use_bias=True)(inputs)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layer1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    layers = tf.keras.layers.Concatenate()([layer1, layer1, layer1])\n",
    "    #Layer 2\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 3\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 4\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 5\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    layers = tf.keras.layers.Concatenate()([layers, layers, layers])\n",
    "    layers = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
    "    \n",
    "    #Layer 10, FC, Softmax\n",
    "    layers = tf.keras.layers.Dense(128,activation=\"relu\")(layers)\n",
    "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "    layers = tf.keras.layers.Dense(64 ,activation=\"relu\")(layers)\n",
    "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "    layers = tf.keras.layers.Dense(32 ,activation=\"relu\")(layers)\n",
    "    predictions = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output_1\")(layers)\n",
    "    \n",
    "    #Compilador\n",
    "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "    optimizer=tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9) \n",
    "    if compile:\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERACIÓN DEL MODELO Y GUARDADO EN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_conv_model_A(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZACIÓN GRÁFICA DEL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENTRENAMIENTO DEL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, batch_size=64, epochs=30, model_name=\"YeNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LUEGO DE HABERLO ENTRENADO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos el mejor modelo para evaluar sobre la mejor época en Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto se hace pues en el paper de Zhu-Net los autores mencionan que cargan el mejor modelo obtenido sobre determinada época y son ésos los valores que presentan, el verbose=0, es bueno usarlo en TensorFlow 2, debido a que de lo contrario saldrán un montón de barritas de carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/media/ia/Datos1/DocReinel/Steganalysis/Ye-net/Ye-Net-Keras-TensorFlow/logs/YeNet_PRUEBA2_DATA_1581272457.8803444/saved-model-28-0.81.hdf5', custom_objects={'TLU3':TLU3}, compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy = model.evaluate(Z,Zt,verbose=0)\n",
    "print(f'Loss={loss:.4f} y Accuracy={accuracy:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZACIÓN DE LOS FILTROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtros de las capas convolucionales\n",
    "# summarize filter shapes\n",
    "for layer in model.layers:\n",
    "    # check for convolutional layer\n",
    "    if 'conv' not in layer.name:\n",
    "        continue\n",
    "    # get filter weights\n",
    "    filters, biases = layer.get_weights()\n",
    "    print(layer.name, filters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()\n",
    "for i in weights:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para ver los filtros\n",
    "def display_filters(w, figsize=(15,15)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    w = (w-np.min(w))/(np.max(w)-np.min(w))\n",
    "    cont=0\n",
    "    for i in range(w.shape[-1]):\n",
    "        for j in range(w.shape[-2]):\n",
    "            #print(w.shape[-2],w.shape[-1],cont)\n",
    "            cont=cont+1\n",
    "            plt.subplot(w.shape[-2],w.shape[-1],cont)\n",
    "            plt.imshow(w[:,:,0,i], interpolation=\"none\", cmap='gray')\n",
    "            plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtro 1\n",
    "w0 = model.get_weights()[0]\n",
    "print (w0.shape)\n",
    "type(display_filters(w0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtro 2\n",
    "w0 = model.get_weights()[5]\n",
    "print (w0.shape)\n",
    "type(display_filters(w0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtro 3\n",
    "w0 = model.get_weights()[10]\n",
    "print (w0.shape)\n",
    "type(display_filters(w0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtro 4\n",
    "w0 = model.get_weights()[15]\n",
    "print (w0.shape)\n",
    "type(display_filters(w0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtro 5\n",
    "w0 = model.get_weights()[20]\n",
    "print (w0.shape)\n",
    "type(display_filters(w0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADICIONALEMTE TENEMOS PRUEBAS Y MODELOS PREVIOS A LA YE-NET COMPLETAMENTE MEJORADA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Según un paper al usar sólo 10 SRM elegidos se lograba mejores resultados, lo cual no fué así en ésta arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZACIÓN GRÁFICA DE UN FILTRO, Y DE LOS 30SRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srm_weights = np.load('SRM_Kernels.npy')\n",
    "def display_filters(w, figsize=(100,100)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    w = (w-np.min(w))/(np.max(w)-np.min(w))\n",
    "    cont=0\n",
    "    for i in range(w.shape[-1]):\n",
    "        for j in range(w.shape[-2]):\n",
    "            cont=cont+1\n",
    "            plt.subplot(w.shape[-2],w.shape[-1],cont)\n",
    "            plt.imshow(w[:,:,0,i], interpolation=\"none\", cmap='gray')\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "display_filters(srm_weights[:,:,:,0:1])\n",
    "print(srm_weights[:,:,:,1:2].shape)  \n",
    "display_filters(srm_weights)\n",
    "print(srm_weights.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACIÓN DE LOS FILTROS QUE DECIA EN EL PAPER FUERON LOS MEJORES PARA LA ARQUITECTUTA. SE MUESTRAN VISUALMENTE Y SE GUARDAN EN UN ARCHIVO .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=srm_weights[:,:,:,10:12]\n",
    "b=srm_weights[:,:,:, 8:10]\n",
    "c=srm_weights[:,:,:,14:15]\n",
    "e=srm_weights[:,:,:,16:17]\n",
    "f=srm_weights[:,:,:,12:14]\n",
    "g=srm_weights[:,:,:,23:24]\n",
    "h=srm_weights[:,:,:,25:26]\n",
    "SRM10 = np.concatenate((a,b,c,e,f,g,h),axis=3)\n",
    "\n",
    "display_filters(SRM10)\n",
    "print(SRM10.shape)\n",
    "np.save('10SRM_Kernels.npy', SRM10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SE PROBARON DISTINTAS CONFIGURACIONES CON LOS 10SRM ELEGIDOS, UNA DE ELLAS ES LA MOSTRADA A CONTINUACIÓN QUE CONSISTE EN CONCATENAR LOS 10SRM PARA TENER 30SRM PERO YA SÓLO DE LOS ELEGIDOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRM30full=np.concatenate((SRM10[:,:,:,:],SRM10[:,:,:,:],SRM10[:,:,:,:]),axis=3) \n",
    "print(SRM30full.shape)\n",
    "\n",
    "display_filters(SRM30full)\n",
    "srm_weights = SRM30full\n",
    "biasSRM=numpy.ones(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNA PRUEBA INTERESANTE TAMBIÉN FUÉ UNIR LOS 30SRM ORIGINALES CON LOS 10SRM ELEGIDOS, SIN EMBARGO LOS RESULTADOS NO MEJORARON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#40SRM\n",
    "##################################################SRM FILTER\n",
    "srm_weights10 = np.load('10SRM_Kernels.npy')\n",
    "print (srm_weights10.shape)\n",
    "srm_weights30 = np.load('SRM_Kernels.npy')\n",
    "print (srm_weights30.shape)\n",
    "\n",
    "srm_weights40 = np.concatenate((srm_weights10,srm_weights30),axis=3)\n",
    "print(srm_weights40.shape)\n",
    "\n",
    "biasSRM40=numpy.ones(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se hizo pruebas mediante la inicialización con los filtros de Alex-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En una de las pruebas se usó la siguiente primera capa: \n",
    "\n",
    "layers = tf.keras.layers.Conv2D(96, (11,11), kernel_initializer=ALEX_FILTER, trainable=False, strides=(1,1), activation=TLU3)(inputs) #Alex-Net\n",
    "\n",
    "Se probó extrayendo casa uno de los niveles RGB, y se probó, sin embargo no se obtuvo resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos el filtro de la primera convolución de Alex-Net\n",
    "import mlutils\n",
    "alex_weights = np.load('/media/ia/Datos1/DocReinel/Steganalysis/Ye-net/Ye-Net-Keras-TensorFlow/Otros/Alex_Filter/dict_alexnet_filters.npy', allow_pickle=True, encoding='bytes').item()\n",
    "Alex=alex_weights[\"conv1\"][0]\n",
    "#Alex #See the filter values\n",
    "print(Alex.shape)\n",
    "mlutils.display_imgs(Alex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos un nuevo .npy sólo con los filtros de la convolución 1 RGB\n",
    "data_array = np.array(Alex, dtype=float32)\n",
    "np.save('conv1_alexnet_filter_(11,11,3,96).npy', data_array)\n",
    "data_array = np.load('conv1_alexnet_filter_(11,11,3,96).npy')\n",
    "\n",
    "def ALEX_FILTER(shape, dtype=None, partition_info=None):\n",
    "    filAlex=data_array\n",
    "    return filAlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data_array[:,:,2,:] \n",
    "print(x.shape)\n",
    "Alex_Fil = np.expand_dims(x, axis=2)\n",
    "\n",
    "#Guardamos un nuevo .npy sólo con los filtros de la convolución 1 UN CANAL\n",
    "Alex_Filter = np.array(Alex_Fil, dtype=float32)\n",
    "np.save('conv1_alexnet_filter_(11,11,1,96).npy', Alex_Filter)\n",
    "Alex_Filter = np.load('conv1_alexnet_filter_(11,11,1,96).npy')\n",
    "\n",
    "print(Alex_Filter.shape)\n",
    "def ALEX_FILTER(shape, dtype=None, partition_info=None):\n",
    "    filAlex=Alex_Filter\n",
    "    return filAlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_filters(w, figsize=(100,100)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    w = (w-np.min(w))/(np.max(w)-np.min(w))\n",
    "    cont=0\n",
    "    for i in range(w.shape[-1]):\n",
    "        for j in range(w.shape[-2]):\n",
    "            #print(w.shape[-2],w.shape[-1],cont)\n",
    "            cont=cont+1\n",
    "            plt.subplot(w.shape[-2],w.shape[-1],cont)\n",
    "            plt.imshow(w[:,:,0,i], interpolation=\"none\", cmap='gray')\n",
    "            plt.axis(\"off\")\n",
    "print(Alex_Filter.shape)            \n",
    "display_filters(Alex_Filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO CUANDO SE USÓ LA TLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#74% PRECISIÓN\n",
    "def get_conv_model_A(num_classes, img_size=256, compile=True):\n",
    "    tf.reset_default_graph()\n",
    "    tf.keras.backend.clear_session()\n",
    "    print (\"using\",num_classes,\"classes\")\n",
    "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
    "    \n",
    "    #Layer 1\n",
    "    layers = tf.keras.layers.Conv2D(30, (5,5), kernel_initializer=SRM, strides= (1,1), trainable=False)(inputs)\n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    tf.clip_by_value(layers, clip_value_min=-tlu_threshold3, clip_value_max=tlu_threshold3, name='TLU_3')\n",
    "    \n",
    "    #Layer 2\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    \n",
    "    #Layer 3\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    \n",
    "    #Layer 4\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 5\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 6\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 7\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 8\n",
    "    layers = tf.keras.layers.Conv2D(16, (3,3), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    \n",
    "    #Layer 9\n",
    "    layers = tf.keras.layers.Conv2D(16, (3,3), strides= (3,3), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    \n",
    "    #Layer 10, FC, Softmax\n",
    "    layers = tf.keras.layers.Flatten()(layers)\n",
    "    layers = tf.keras.layers.Dense(256, activation=\"relu\")(layers)\n",
    "    layers = tf.keras.layers.Dropout(0.5)(layers)\n",
    "    layers = tf.keras.layers.Dense(128, activation=\"relu\")(layers)\n",
    "    layers = tf.keras.layers.Dropout(0.5)(layers)\n",
    "    predictions = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output_1\")(layers)\n",
    "    \n",
    "    #Compilador\n",
    "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adadelta(lr=0.4, rho=0.95)\n",
    "    if compile:\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO YE-NET EN TENSORFLOW CON KERAS DE FORMA NATIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras \n",
    "#YE-NET IMPLEMENTADA EN tf.keras \n",
    "#DOS OPCIONES---> EN LAYER 1: \n",
    "###trainable=False[Converge rápido, perdida alta] \n",
    "###y sin usar trainable=False[Converge lento, perdida baja] \n",
    "\n",
    "def get_conv_model_A(num_classes, img_size=256):\n",
    "    tf.reset_default_graph()\n",
    "    tf.keras.backend.clear_session()\n",
    "    print (\"using\",num_classes,\"classes\")\n",
    "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
    "    \n",
    "    #Layer 1\n",
    "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,bias], strides= (1,1), activation=TLU3)(inputs)\n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    \n",
    "    #Layer 2\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    \n",
    "    #Layer 3\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    \n",
    "    #Layer 4\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 5\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 6\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 7\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 8\n",
    "    layers = tf.keras.layers.Conv2D(16, (3,3), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    \n",
    "    #Layer 9\n",
    "    layers = tf.keras.layers.Conv2D(16, (3,3), strides= (3,3), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.contrib.layers.batch_norm(layers, decay=0.6, epsilon=0.001)\n",
    "    \n",
    "    #Layer 10, FC, Softmax\n",
    "    layers = tf.keras.layers.Flatten()(layers)\n",
    "    predictions = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output_1\")(layers)\n",
    "    \n",
    "    #Compilador\n",
    "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adadelta(lr=0.4, rho=0.95)\n",
    "    model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO YE-NET EN TENSORFLOW CON KERAS MODIFICADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras\n",
    "#YE-NET CON CAPA DE VALOR ABSOLUTO(Mejoras en el valor de precisión), Y CON LA CAPA DENSA DE CANCER(Mejoras en la perdida)\n",
    "#Con un optimizador RMSprop(lr=0.001, rho=0.9) (Estabilidad en la converencia, sin sacrificar la perdida)\n",
    "#Con batch_size=64, epochs=50\n",
    "def get_conv_model_A(num_classes, img_size=256, compile=True):\n",
    "    tf.reset_default_graph()\n",
    "    tf.keras.backend.clear_session()\n",
    "    print (\"using\",num_classes,\"classes\")\n",
    "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
    "    \n",
    "    #Layer 1\n",
    "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,bias], strides= (1,1), trainable=False, activation=TLU3, use_bias=True)(inputs)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=0.001)(layers)\n",
    "    \n",
    "    #Layer 2\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(decay=0.9, epsilon=0.001)(layers)\n",
    "    \n",
    "    #Layer 3\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=0.001)(layers)\n",
    "    \n",
    "    #Layer 4\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=0.001)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 5\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=0.001)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 6\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=0.001)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 7\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=0.001)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 8\n",
    "    layers = tf.keras.layers.Conv2D(16, (3,3), strides= (1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=0.001)(layers)\n",
    "    \n",
    "    #Layer 9\n",
    "    layers = tf.keras.layers.Conv2D(16, (3,3), strides= (3,3), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=0.001)(layers)\n",
    "    \n",
    "    #Layer 10, FC, Softmax\n",
    "    layers = tf.keras.layers.Flatten()(layers)\n",
    "    ################################################################\n",
    "    layers = tf.keras.layers.Dense(128,activation=\"relu\")(layers)\n",
    "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "    layers = tf.keras.layers.Dense(64 ,activation=\"relu\")(layers)\n",
    "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "    layers = tf.keras.layers.Dense(32 ,activation=\"relu\")(layers)\n",
    "    ################################################################\n",
    "    predictions = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output_1\")(layers)\n",
    "    \n",
    "    #Compilador\n",
    "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "    \n",
    "    optimizer=tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9) #1 #Bueno, converge rápido, tocó el 78%en la época 40, y conservó sobre 77% USAR 70 O 75 EPOCHS\n",
    "    \n",
    "    if compile:\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nativo sólo con Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Con Keras\n",
    "model = Sequential()\n",
    "#Layer 1\n",
    "model.add(Convolution2D(30, (5,5), weights=[srm_weights,bias], strides=(1,1), trainable=False, activation=TLU3, input_shape=(256,256,1)))\n",
    "model.add(BatchNormalization(epsilon=0.001, scale=False))\n",
    "\n",
    "#Layer 2\n",
    "model.add(Convolution2D(30, (3,3), strides=(1,1), activation='relu', kernel_initializer='glorot_normal')) #use_bias=True, bias_initializer=Constant(0.2), \n",
    "model.add(BatchNormalization(epsilon=0.001, scale=False))\n",
    "\n",
    "#Layer 3\n",
    "model.add(Convolution2D(30, (3,3), strides=(1,1), activation='relu', kernel_initializer='glorot_normal')) #use_bias=True, bias_initializer=Constant(0.2), \n",
    "model.add(BatchNormalization(epsilon=0.001, scale=False))\n",
    "\n",
    "#Layer 4\n",
    "model.add(Convolution2D(30, (3,3), strides=(1,1), activation='relu', kernel_initializer='glorot_normal')) #use_bias=True, bias_initializer=Constant(0.2), \n",
    "model.add(BatchNormalization(epsilon=0.001, scale=False))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "#Layer 5\n",
    "model.add(Convolution2D(32, (5,5), strides=(1,1), activation='relu', kernel_initializer='glorot_normal')) #use_bias=True, bias_initializer=Constant(0.2), \n",
    "model.add(BatchNormalization(epsilon=0.001, scale=False))\n",
    "model.add(AveragePooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "#Layer 6\n",
    "model.add(Convolution2D(32, (5,5), strides=(1,1), activation='relu', kernel_initializer='glorot_normal')) #use_bias=True, bias_initializer=Constant(0.2), \n",
    "model.add(BatchNormalization(epsilon=0.001, scale=False))\n",
    "model.add(AveragePooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "#Layer 7\n",
    "model.add(Convolution2D(32, (5,5), strides=(1,1), activation='relu', kernel_initializer='glorot_normal')) #use_bias=True, bias_initializer=Constant(0.2), \n",
    "model.add(BatchNormalization(epsilon=0.001, scale=False))\n",
    "model.add(AveragePooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "#Layer 8\n",
    "model.add(Convolution2D(16, (3,3), strides=(1,1), activation='relu', kernel_initializer='glorot_normal')) #use_bias=True, bias_initializer=Constant(0.2), \n",
    "model.add(BatchNormalization(epsilon=0.001, scale=False))\n",
    "\n",
    "#Layer 9\n",
    "model.add(Convolution2D(16, (3,3), strides=(3,3), activation='relu', kernel_initializer='glorot_normal')) #use_bias=True, bias_initializer=Constant(0.2), \n",
    "model.add(BatchNormalization(epsilon=0.001, scale=False))\n",
    "\n",
    "#Layer 10, FC, Softmax\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax')) #, kernel_initializer=RandomNormal(mean=0.0, stddev=0.01), use_bias=True, bias_initializer='zeros'\n",
    "\n",
    "#Estructura del modelo\n",
    "model.summary()\n",
    "#COMPILADOR Y FIT\n",
    "opt=optimizers.Adadelta(lr=0.4, rho=0.95)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modificado sólo con Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Con Keras [Modificaciones]\n",
    "model = Sequential()\n",
    "#Layer 1\n",
    "model.add(Convolution2D(30, (5,5), weights=[srm_weights,bias], strides=(1,1), trainable=False, use_bias=True, bias_initializer='zeros', padding='valid', data_format=\"channels_last\", input_shape=(256,256,1))) #probar quitando use_bias=True, bias_initializer='zeros' segun tensormaster\n",
    "model.add(Activation(TLU3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#Layer 2\n",
    "model.add(Convolution2D(30, (3,3), strides= (1,1), activation='relu', kernel_regularizer=regularizers.l2(5e-4), use_bias=True, bias_initializer=Constant(0.2), padding='valid', data_format=\"channels_last\", kernel_initializer='glorot_normal')) #probar glorot_uniform\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#Layer 3\n",
    "model.add(Convolution2D(30, (3,3), strides= (1,1), activation='relu', kernel_regularizer=regularizers.l2(5e-4), use_bias=True, bias_initializer=Constant(0.2), padding='valid', data_format=\"channels_last\", kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#Layer 4\n",
    "model.add(Convolution2D(30, (3,3), strides= (1,1), activation='relu', kernel_regularizer=regularizers.l2(5e-4), use_bias=True, bias_initializer=Constant(0.2), padding='valid', data_format=\"channels_last\", kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=(1, 1))) #tensor-master\n",
    "\n",
    "#Layer 5\n",
    "model.add(Convolution2D(32, (5,5), strides= (1,1), activation='relu', kernel_regularizer=regularizers.l2(5e-4), use_bias=True, bias_initializer=Constant(0.2), padding='valid', data_format=\"channels_last\", kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "#Layer 6\n",
    "model.add(Convolution2D(32, (5,5), strides= (1,1), activation='relu', kernel_regularizer=regularizers.l2(5e-4), use_bias=True, bias_initializer=Constant(0.2), padding='valid', data_format=\"channels_last\", kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(AveragePooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(AveragePooling2D(pool_size=(3, 3), strides=(3, 3))) #tensor-master\n",
    "\n",
    "#Layer 7\n",
    "model.add(Convolution2D(32, (5,5), strides= (1,1), activation='relu', kernel_regularizer=regularizers.l2(5e-4), use_bias=True, bias_initializer=Constant(0.2), padding='valid', data_format=\"channels_last\", kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(AveragePooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(AveragePooling2D(pool_size=(3, 3), strides=(4, 4))) #tensor-master\n",
    "\n",
    "#Layer 8\n",
    "model.add(Convolution2D(16, (3,3), strides= (1,1), activation='relu', kernel_regularizer=regularizers.l2(5e-4), use_bias=True, bias_initializer=Constant(0.2), padding='valid', data_format=\"channels_last\", kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#Layer 9\n",
    "model.add(Convolution2D(16, (3,3), strides= (3,3), activation='relu', kernel_regularizer=regularizers.l2(5e-4), use_bias=True, bias_initializer=Constant(0.2), padding='valid', data_format=\"channels_last\", kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#Layer 10, FC, Softmax\n",
    "model.add(Flatten()) #Probar con dos capas densas con 256 y 128 neuronas\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax', kernel_initializer=RandomNormal(mean=0.0, stddev=0.01), use_bias=True, bias_initializer='zeros', kernel_constraint=None)) #probar con activation='softmax' segun tensormaster, y quitando kernel_constraint=None, probar bias_initializer=Constant(0.0)\n",
    "\n",
    "#Estructura del modelo\n",
    "model.summary()\n",
    "#COMPILADOR Y FIT\n",
    "opt=optimizers.Adadelta(lr=0.4, rho=0.95)\n",
    "model.compile(loss='binary_crossentropy',optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas sobre el optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################\n",
    "#optimizer = tf.keras.optimizers.Adadelta(lr=0.4, rho=0.95, decay=5e-6) #With 50 epochs --> 67,65%Yedroudj\n",
    "#optimizer = tf.keras.optimizers.Adadelta(lr=0.4, rho=0.95, decay=0.01) #With 50 epochs --> 66,90%Yedroudj\n",
    "#optimizer = tf.keras.optimizers.Adadelta(lr=0.4, rho=0.95)#funciona_bien_primeras pruebas 80 --> 77,85%Bra\n",
    "#################################################################################################################\n",
    "    \n",
    "###optimizer=tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False) #3 #26 epochs supera Yedroudj-Net, perdida alta\n",
    "###optimizer = tf.keras.optimizers.Adadelta(lr=0.6, rho=0.95) #2 #65 epochs --> 78,25%Bra\n",
    "###optimizer=tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9) #1 #Bueno, converge rápido, tocó el 78%en la época 40, y conservó sobre 77% USAR 70 O 75 EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI QUEREMOS QUE LA CURVA GENERADA DE TRAIN Y VALIDACIÓN EN LOSS Y EN PRECISIÓN SEAN ESTABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para decidir que la mejor opción es un valor de 0.1 en el rate del spatial dropout se han hecho muchas pruebas, se ha tuneado el valor con los siguientes:\n",
    "\n",
    "dropout_values = [0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6]\n",
    "\n",
    "dropout_values = [0.03, 0.02, 0.01, 0.08, 0.065, 0.075, 0.085, 0.09]\n",
    "\n",
    "dropout_values = [0.07, 0.06, 0.05, 0.04, 0.03, 0.02, 0.01, 0.08]\n",
    "\n",
    "dropout_values = [0.1, 0.08] como candidatos finales\n",
    "\n",
    "Así se podría al mejor modelo aplicarle spatial_dropout para ver su comportamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo sin reducir las capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoca 125, 81.10% precisión, en la época 1296, 82.45% precisión sobre validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 experimento SPATIAL DROPOUT HA SIDO EL MEJOR pero ya con 500 épocas\n",
    "def get_conv_model_A(num_classes, img_size=256, compile=True):\n",
    "    tf.reset_default_graph()\n",
    "    tf.keras.backend.clear_session()\n",
    "    print (\"using\",num_classes,\"classes\")\n",
    "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
    "    \n",
    "    #Layer 1\n",
    "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=TLU3, use_bias=True)(inputs)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 2\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 3\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 4\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 5\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 6\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 7\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 8\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(16, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 9\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(16, (3,3), strides=(3,3), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 10, FC, Softmax\n",
    "    #layers = tf.keras.layers.Flatten()(layers)\n",
    "    layers = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layers) #Yedroudj-Net en 12 epocas\n",
    "    layers = tf.keras.layers.Dense(128,activation=\"relu\")(layers)\n",
    "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "    layers = tf.keras.layers.Dense(64 ,activation=\"relu\")(layers)\n",
    "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "    layers = tf.keras.layers.Dense(32 ,activation=\"relu\")(layers)\n",
    "    predictions = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output_1\")(layers)\n",
    "    \n",
    "    #Compilador\n",
    "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "    optimizer=tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9) \n",
    "    if compile:\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_conv_model_A(2)\n",
    "model.summary()\n",
    "train(model, batch_size=64, epochs=1300, model_name=\"5Dropout0.1_Ye-Net_initialLayer2_with1300epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buena opción con del valor para el spatial dropout 100 epocas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oscila en 80% en validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yedroudj-Net en la época 22\n",
    "def get_conv_model_A(num_classes, img_size=256, compile=True):\n",
    "    tf.reset_default_graph()\n",
    "    tf.keras.backend.clear_session()\n",
    "    print (\"using\",num_classes,\"classes\")\n",
    "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
    "    \n",
    "    #Layer 1\n",
    "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=TLU3, use_bias=True)(inputs)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 2\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.07)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 3\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.07)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 4\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.07)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 5\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.07)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 6\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.07)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 7\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.07)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 8\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.07)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(16, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 9\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.07)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(16, (3,3), strides=(3,3), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 10, FC, Softmax\n",
    "    #layers = tf.keras.layers.Flatten()(layers)\n",
    "    layers = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
    "    layers = tf.keras.layers.Dense(128,activation=\"relu\")(layers)\n",
    "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "    layers = tf.keras.layers.Dense(64 ,activation=\"relu\")(layers)\n",
    "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "    layers = tf.keras.layers.Dense(32 ,activation=\"relu\")(layers)\n",
    "    predictions = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output_1\")(layers)\n",
    "    \n",
    "    #Compilador\n",
    "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "    optimizer=tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9) \n",
    "    if compile:\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#Yedroudj-Net en 12 epocas\n",
    "model = get_conv_model_A(2)\n",
    "model.summary()\n",
    "train(model, batch_size=64, epochs=100, model_name=\"Ye-Net-BuenDropout0.07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO V1 EL MEJOR CON TODAS LAS CONVOLUCIONALES DE YE-NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRECISIÓN CERCANA AL 80%\n",
    "def get_conv_model_A(num_classes, img_size=256, compile=True):\n",
    "   # tf.reset_default_graph()\n",
    "    tf.keras.backend.clear_session()\n",
    "    print (\"using\",num_classes,\"classes\")\n",
    "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
    "    \n",
    "    #Layer 1\n",
    "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=TLU3, use_bias=True)(inputs)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 2\n",
    "    #layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 3\n",
    "    #layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 4\n",
    "    #layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 5\n",
    "    #layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 6\n",
    "    #layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 7\n",
    "    #layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((3,3), strides= (2,2))(layers)\n",
    "    \n",
    "    #Layer 8\n",
    "    #layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(16, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 9\n",
    "    #layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(16, (3,3), strides=(3,3), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    \n",
    "    #Layer 10, FC, Softmax\n",
    "    layers = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
    "    layers = tf.keras.layers.Dense(128,activation=\"relu\")(layers)\n",
    "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "    layers = tf.keras.layers.Dense(64 ,activation=\"relu\")(layers)\n",
    "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "    layers = tf.keras.layers.Dense(32 ,activation=\"relu\")(layers)\n",
    "    predictions = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output_1\")(layers)\n",
    "    \n",
    "    #Compilador\n",
    "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "    optimizer=tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9) \n",
    "    if compile:\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTROS MODELOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelo interesante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precisión máxima sobre validación 81,45%\n",
    "inputs = tf.keras.Input(shape=(256,256,1), name=\"input_1\")\n",
    "\n",
    "#Layer 1\n",
    "layer1 = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=TLU3, use_bias=True)(inputs)\n",
    "layer1 = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer1)\n",
    "layer1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer1)\n",
    "    \n",
    "\n",
    "#Layer 1\n",
    "layer2 = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=TLU3, use_bias=True)(inputs)\n",
    "layer2 = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer2)\n",
    "layer2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer2)\n",
    "    \n",
    "print(layer1.shape)\n",
    "print(layer2.shape)\n",
    "layer3 = tf.keras.layers.add([layer1, layer2])\n",
    "print(layer3.shape)\n",
    "\n",
    "#Layer 2\n",
    "layer = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layer3) \n",
    "layer = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer)\n",
    "layer = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer)\n",
    "    \n",
    "#Layer 3\n",
    "layer = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layer) \n",
    "layer = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer)\n",
    "layer = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer)\n",
    "    \n",
    "#Layer 4\n",
    "layer = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layer) \n",
    "layer = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer)\n",
    "layer = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer)\n",
    "layer = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layer)\n",
    "    \n",
    "#Layer 5\n",
    "layer = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layer)\n",
    "layer = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer)\n",
    "layer = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Layer 10, FC, Softmax\n",
    "layer4 = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layer)\n",
    "layer4 = tf.keras.layers.Dense(128,activation=\"relu\")(layer4)\n",
    "layer4 = tf.keras.layers.Dropout(0.2)(layer4)\n",
    "layer4 = tf.keras.layers.Dense(64 ,activation=\"relu\")(layer4)\n",
    "layer4 = tf.keras.layers.Dropout(0.2)(layer4)\n",
    "layer4 = tf.keras.layers.Dense(32 ,activation=\"relu\")(layer4)\n",
    "predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layer4)\n",
    "    \n",
    "#######################################    \n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True) \n",
    "    \n",
    "#######################################\n",
    "    \n",
    "#Compilador\n",
    "model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr_schedule, rho=0.9) \n",
    "model.compile(optimizer=optimizer,\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelo tridireccional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sólo 68% de precisión\n",
    "inputs = tf.keras.Input(shape=(256,256,1), name=\"input_1\")\n",
    "######################################################################YE-NET\n",
    "layer1 = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=TLU3, use_bias=True)(inputs)\n",
    "layer1 = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer1)\n",
    "layer1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer1)\n",
    "layer1 = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layer1) \n",
    "layer1 = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer1)\n",
    "layer1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer1)\n",
    "layer1 = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layer1) \n",
    "layer1 = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer1)\n",
    "layer1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer1)\n",
    "layer1 = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layer1) \n",
    "layer1 = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer1)\n",
    "layer1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer1)\n",
    "layer1 = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layer1)\n",
    "layer1 = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layer1)\n",
    "layer1 = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer1)\n",
    "layer1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer1)\n",
    "layer1 = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layer1)\n",
    "layer1 = tf.keras.layers.Dense(128,activation=\"relu\")(layer1)\n",
    "layer1 = tf.keras.layers.Dropout(0.2)(layer1)\n",
    "layer1 = tf.keras.layers.Dense(64 ,activation=\"relu\")(layer1)\n",
    "layer1 = tf.keras.layers.Dropout(0.2)(layer1)\n",
    "layer1 = tf.keras.layers.Dense(32 ,activation=\"relu\")(layer1)\n",
    "layer1 = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1Ye-Net\")(layer1)\n",
    "\n",
    "###############################################################XU-NET\n",
    "layer2 = tf.keras.layers.Conv2D(30,(5,5), weights=[srm_weights,biasSRM], trainable=False, padding=\"same\", data_format=\"channels_last\",activation='tanh')(inputs)\n",
    "layer2 = tf.keras.layers.Conv2D(16,(5,5), activation=\"tanh\", padding=\"same\", data_format=\"channels_last\",kernel_initializer='glorot_normal')(layer2)\n",
    "layer2 = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer2)\n",
    "layer2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer2)\n",
    "layer2 = tf.keras.layers.AveragePooling2D((5,5),strides=2, padding=\"same\", data_format=\"channels_last\")(layer2)\n",
    "layer2 = tf.keras.layers.Conv2D(32,(5,5), activation=\"tanh\",padding=\"same\", data_format=\"channels_last\",kernel_initializer='glorot_normal')(layer2)\n",
    "layer2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer2)\n",
    "layer2 = tf.keras.layers.AveragePooling2D((5,5),strides=2, padding=\"same\", data_format=\"channels_last\")(layer2) \n",
    "layer2 = tf.keras.layers.Conv2D(64,(1,1), activation=\"relu\", padding=\"same\", data_format=\"channels_last\",kernel_initializer='glorot_normal')(layer2)\n",
    "layer2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer2)\n",
    "layer2 = tf.keras.layers.AveragePooling2D((5,5),strides=2, padding=\"same\", data_format=\"channels_last\")(layer2)\n",
    "layer2 = tf.keras.layers.Conv2D(128,(1,1), activation=\"relu\",padding=\"same\", data_format=\"channels_last\",kernel_initializer='glorot_normal')(layer2)\n",
    "layer2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer2)\n",
    "layer2 = tf.keras.layers.AveragePooling2D((5,5),strides=2, padding=\"same\", data_format=\"channels_last\")(layer2)\n",
    "layer2 = tf.keras.layers.Conv2D(256,(1,1), activation=\"relu\",padding=\"same\", data_format=\"channels_last\",kernel_initializer='glorot_normal')(layer2)\n",
    "layer2 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer2)\n",
    "layer2 = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_first\")(layer2)\n",
    "layer2 = tf.keras.layers.Dense(128,activation=\"softmax\",name=\"output_1\")(layer2)\n",
    "layer2 = tf.keras.layers.Dense(64,activation=\"softmax\",name=\"output_2\")(layer2)\n",
    "layer2 = tf.keras.layers.Dense(32,activation=\"softmax\",name=\"output_4\")(layer2)\n",
    "layer2 = tf.keras.layers.Dense(2,activation=\"softmax\",name=\"output_5Xu-net\")(layer2)\n",
    "\n",
    "###############################################################YEDROUDJ-NET\n",
    "layer3 = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=TLU3, use_bias=True)(inputs)\n",
    "layer3 = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer3)\n",
    "layer3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer3)\n",
    "layer3 = tf.keras.layers.Conv2D(30, (5,5), strides=(1,1), activation=TLU3, kernel_initializer='glorot_normal')(layer3) \n",
    "layer3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer3)\n",
    "layer3 = tf.keras.layers.Conv2D(30, (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layer3) \n",
    "layer3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer3)\n",
    "layer3 = tf.keras.layers.AveragePooling2D((5,5), strides= (2,2))(layer3)\n",
    "layer3 = tf.keras.layers.Conv2D(64, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layer3)\n",
    "layer3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer3)\n",
    "layer3 = tf.keras.layers.AveragePooling2D((5,5), strides= (2,2))(layer3)\n",
    "layer3 = tf.keras.layers.Conv2D(128, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layer3)\n",
    "layer3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer3)\n",
    "layer3 = tf.keras.layers.AveragePooling2D((5,5), strides= (2,2))(layer3)\n",
    "layer3 = tf.keras.layers.Conv2D(256, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layer3)\n",
    "layer3 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer3)\n",
    "layer3 = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layer3)\n",
    "layer3 = tf.keras.layers.Dense(256, activation=\"relu\")(layer3)\n",
    "layer3 = tf.keras.layers.Dense(1024, activation=\"relu\")(layer3)\n",
    "layer3 = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1Yedroudj-Net\")(layer3)\n",
    "\n",
    "\n",
    "print(layer1.shape)\n",
    "print(layer2.shape)\n",
    "print(layer3.shape)\n",
    "predictions = tf.keras.layers.add([layer1, layer2, layer3])*(1/3)\n",
    "print(predictions.shape)\n",
    "\n",
    "#Compilador\n",
    "model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "optimizer=tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9) \n",
    "model.compile(optimizer=optimizer,\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelo con shortcuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No genera resultados superiores al 80% pese a su complejidad\n",
    "inputs = tf.keras.Input(shape=(256,256,1), name=\"input_1\")\n",
    "    \n",
    "#Layer 1\n",
    "layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=TLU3, use_bias=True)(inputs)\n",
    "layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "layers1 = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
    "\n",
    "#Layer 2\n",
    "layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "layers2 = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
    "#layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
    "\n",
    "#Layer 3\n",
    "layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "layers3 = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
    "#layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
    "\n",
    "#Layer 4\n",
    "layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers) \n",
    "layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "layers4 = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
    "#layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
    "    \n",
    "#Layer 5\n",
    "layers = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal')(layers)\n",
    "layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "layers5 = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
    "\n",
    "layers = tf.keras.layers.concatenate([layers1,layers2,layers3,layers4,layers5])\n",
    "#Layer 10, FC, Softmax\n",
    "layers = tf.keras.layers.Dense(128,activation=\"relu\")(layers)\n",
    "layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "layers = tf.keras.layers.Dense(64 ,activation=\"relu\")(layers)\n",
    "layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "layers = tf.keras.layers.Dense(32 ,activation=\"relu\")(layers)\n",
    "predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layers)\n",
    "        \n",
    "#Compilador\n",
    "model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "optimizer=tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9) \n",
    "model.compile(optimizer=optimizer,\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_layer_names=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://wallpapercave.com/wp/wp3169267.jpg>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
